# Multilingual lexicography automation
**The Etica.AI + HXL-CPLP [monorepo](https://en.wikipedia.org/wiki/Monorepo) with public domain automation scripts for [practical lexicography](https://en.wikipedia.org/wiki/Lexicography) on selected topics. Goal of both compilation of existing translations ([such as Wikidata](https://www.wikidata.org/wiki/Wikidata:Licensing)) and preparation for new terminology translation initiatives.**

More about on:
- https://github.com/EticaAI/numerordinatio/issues/5
- https://numerordinatio.etica.ai/

<!--
## https://stackoverflow.com/questions/2317652/nested-git-repositories-without-submodules
# cd /workspace/git/EticaAI
# ln -s /workspace/git/EticaAI/multilingual-lexicography-automation/officinam /workspace/git/EticaAI/n-data 

cd /workspace/git/EticaAI/n-data-pseudobase
git --git-dir /workspace/git/EticaAI/n-data.git-metadata --work-tree /workspace/git/EticaAI/multilingual-lexicography-automation/officinam status
git --git-dir /workspace/git/EticaAI/n-data.git-metadata --work-tree /workspace/git/EticaAI/multilingual-lexicography-automation/officinam gui
-->

## License

> TODO: explain that at least part of generated datasets are granted to have incompatible licenses with each other, even for humanitarian use / emergency response.


<!--
- To watch later
  - https://github.com/Wikidata
  - Is possible to create bots? Nice
    - https://github.com/LeMyst/WikibaseIntegrator
- https://github.com/maxlath/wikibase-cli

-->